{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20244950",
   "metadata": {},
   "source": [
    "# Board games scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgg_top(n_pages=20, start_page=1):\n",
    "    '''\n",
    "    On this script you can get list of top board games from boardgamegeek.com\n",
    "    -----\n",
    "    Paramrters\n",
    "    -----\n",
    "    n_pages: how many pages you searh, default - 20, because without sighning in on boardgamegeek.com you can load only first 20 pages\n",
    "    start_page: from this page we start scrapping, default - 1.\n",
    "    '''\n",
    "    url_main = 'https://boardgamegeek.com'\n",
    "    url_searh_boardgames = url_main + '/browse/boardgame'\n",
    "    url_page = '/page/'\n",
    "    # n_pages = 20\n",
    "    game_top_list = pd.DataFrame()\n",
    "    for i in range(n_pages):\n",
    "        r = re.get(url_searh_boardgames + url_page + str(start_page+i))\n",
    "        soup = BeautifulSoup(r.text)\n",
    "        rows = soup.find_all('tr', id='row_')\n",
    "        for j, row in enumerate(rows):\n",
    "            rank = row.find('td', class_='collection_rank').find('a').get('name')\n",
    "            gameinfo = row.find('div', id='results_objectname'+str(j+1))\n",
    "            title = gameinfo.find('a').text\n",
    "            try:\n",
    "                year = gameinfo.find('span').text\n",
    "            except:\n",
    "                year = ''\n",
    "            try:\n",
    "                description = row.find('p', class_='smallefont dull').text.strip()\n",
    "            except:\n",
    "                description = ''\n",
    "            link = url_main + gameinfo.find('a').get('href')\n",
    "            game_id = str(gameinfo.find('a').get('href'))[len('/boardgame/'):]\n",
    "            game_id = game_id[:game_id.find('/')]\n",
    "            ratings = row.find_all('td', class_='collection_bggrating')\n",
    "            rat_list = []\n",
    "            for i in ratings:\n",
    "                rat_list.append(i.text.strip())\n",
    "            geek_rating = rat_list[0]\n",
    "            avg_rating = rat_list[1]\n",
    "            num_votes = rat_list[2]\n",
    "\n",
    "            game = {'rank': rank, 'title': title, 'game_id':game_id, 'description':description, 'year':year, 'link': link, \n",
    "                    'geek_rating':geek_rating, 'avg_rating':avg_rating, 'num_votes':num_votes}\n",
    "            game_top_list = pd.concat([game_top_list, pd.DataFrame([game])])\n",
    "\n",
    "    return game_top_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14280911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bgg_categories():\n",
    "    category_list = pd.DataFrame()\n",
    "    url_main = 'https://boardgamegeek.com'\n",
    "    url_cat = 'https://boardgamegeek.com/browse/boardgamecategory'\n",
    "    r = re.get(url_cat)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    table = soup.find('table', class_='forum_table')\n",
    "    rows = table.find_all('a')\n",
    "    for row in rows:\n",
    "        link = url_main + row.get('href')\n",
    "        category = row.text\n",
    "        cat = {'category':category, 'link':link}\n",
    "        category_list = pd.concat([category_list, pd.DataFrame([cat])])\n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d78d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_bgg_game_data(unique_ids):\n",
    "    '''\n",
    "    This function retrieves aggregated game information via the boardgamegeek.com API\n",
    "    \n",
    "    ----------\n",
    "    \n",
    "    unique_ids - list of unique boardgames ids (it is best to feed a list of no more than 50 id)\n",
    "    \n",
    "    ----------\n",
    "    Using API BoardGameGeek:\n",
    "    https://api.geekdo.com/xmlapi/boardgame/37111?stats=1&pricehistory=1&marketplace=1&comments=1\n",
    "\n",
    "    base - https://api.geekdo.com/xmlapi/boardgame\n",
    "    game - /37111 - gameid\n",
    "    params - ?stats=1&pricehistory=1&marketplace=1&comments=1\n",
    "    comments: Show brief user comments on games (set it to 1, absent by default)\n",
    "    stats: Include game statistics (set it to 1, absent by default)\n",
    "    historical: Include historical game statistics (set it to 1, absent by default) - Use from/end parameters to set starting and ending dates. Returns all data starting from 2006-03-18.\n",
    "    from: Set the start date to include historical data (format: YYYY-MM-DD, absent by default )\n",
    "    to: Set the end date to include historical data (format: YYYY-MM-DD, absent by default )\n",
    "    pricehistory: retrieve the marketplace history for this item (set it to 1, absent by default)\n",
    "    marketplace: retrieve the current marketplace listings (set it to 1, absent by default)\n",
    "    '''\n",
    "    url_id = ''\n",
    "    for i in range(len(unique_ids)):\n",
    "        if i == 0:\n",
    "            url_id = unique_ids[i]\n",
    "        else:\n",
    "            url_id += ',' + unique_ids[i]\n",
    "\n",
    "    api_boardgame = 'https://api.geekdo.com/xmlapi/boardgame/'\n",
    "    api_params = '?stats=1&pricehistory=1&marketplace=1&comments=1'\n",
    "    r = re.get(api_boardgame + url_id + api_params)\n",
    "    soup = BeautifulSoup(r.text, 'xml')\n",
    "    list_bg = soup.find_all('boardgame')\n",
    "    games = pd.DataFrame()\n",
    "    for bg in list_bg:\n",
    "    #     get basic info\n",
    "        boardgame_id = bg.get('objectid')\n",
    "        try:\n",
    "            year_published = bg.find('yearpublished').text\n",
    "        except:\n",
    "            year_published = \"\"\n",
    "        try:\n",
    "            minplayers = bg.find('minplayers').text\n",
    "        except:\n",
    "            minplayers = \"\"\n",
    "        try:\n",
    "            maxplayers = bg.find('maxplayers').text\n",
    "        except:\n",
    "            maxplayers = \"\"\n",
    "        try:\n",
    "            minplaytime = bg.find('minplaytime').text\n",
    "        except:\n",
    "            minplaytime = \"\"\n",
    "        try:\n",
    "            maxplaytime = bg.find('maxplaytime').text\n",
    "        except:\n",
    "            maxplaytime = \"\"\n",
    "        try:\n",
    "            title = bg.find('name', primary='true').text\n",
    "        except:\n",
    "            title = \"\"\n",
    "        try:\n",
    "            age = bg.find('age').text\n",
    "        except:\n",
    "            age = \"\"\n",
    "        try:\n",
    "            description = bg.find('description').text\n",
    "        except:\n",
    "            description = \"\"\n",
    "        try:\n",
    "            main_publisher = bg.find('boardgamepublisher').text\n",
    "        except:\n",
    "            main_publisher = \"\"\n",
    "\n",
    "        \n",
    "        publishers = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgamepublisher'):\n",
    "                publishers.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        honors = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgamehonor'):\n",
    "                honors.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        expansions = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgameexpansion'):\n",
    "                expansions.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        accessories = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgameaccessory'):\n",
    "                accessories.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        artists = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgameartist'):\n",
    "                artists.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        mechanics = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgamemechanic'):\n",
    "                mechanics.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        category = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgamecategory'):\n",
    "                category.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        podcast_episodes = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgamepodcastepisode'):\n",
    "                podcast_episodes.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        designers = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgamedesigner'):\n",
    "                designers.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        graphic_designers = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgamegraphicdesigner'):\n",
    "                graphic_designers.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        subdomains = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgamesubdomain'):\n",
    "                subdomains.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "        implementations = []\n",
    "        try:\n",
    "            for i in bg.find_all('boardgameimplementation'):\n",
    "                implementations.append(i.text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #     get info about voting\n",
    "        suggested_numplayers = {}\n",
    "        try:\n",
    "            for i in bg.find('poll').find_all('results'):\n",
    "                numplayers = i.get('numplayers')\n",
    "                dict_vote = {}\n",
    "                for f in i.find_all('result'):\n",
    "                    dict_vote[f.get('value')] = f.get('numvotes')\n",
    "                suggested_numplayers[numplayers] = dict_vote\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #     get all shorts comments\n",
    "        comments = {}\n",
    "        try:\n",
    "            for comment in bg.find_all('comment'):\n",
    "                comments[comment.get('username')] = comment.text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #     get statistics info\n",
    "        stats = bg.find('statistics')\n",
    "        try:\n",
    "            users_rated = stats.find('usersrated').text\n",
    "        except:\n",
    "            users_rated = ''\n",
    "        try:\n",
    "            average_rating = stats.find('average').text\n",
    "        except:\n",
    "            average_rating = ''\n",
    "        try:\n",
    "            bayes_average_rating = stats.find('bayesaverage').text\n",
    "        except:\n",
    "            bayes_average_rating = ''\n",
    "        try:\n",
    "            median = stats.find('median').text\n",
    "        except:\n",
    "            median = ''\n",
    "        try:\n",
    "            stddev = stats.find('stddev').text\n",
    "        except:\n",
    "            stddev = ''\n",
    "        try:\n",
    "            owned = stats.find('owned').text\n",
    "        except:\n",
    "            owned = ''\n",
    "        try:\n",
    "            trading = stats.find('trading').text\n",
    "        except:\n",
    "            trading = ''\n",
    "        try:\n",
    "            wishing = stats.find('wishing').text\n",
    "        except:\n",
    "            wishing = ''\n",
    "        try:\n",
    "            num_of_comments = stats.find('numcomments').text\n",
    "        except:\n",
    "            num_of_comments = ''\n",
    "        try:\n",
    "            num_of_weights = stats.find('numweights').text\n",
    "        except:\n",
    "            num_of_weights = ''\n",
    "        try:\n",
    "            average_weight = stats.find('averageweight').text\n",
    "        except:\n",
    "            average_weight = ''\n",
    "        ranks = {}\n",
    "        try:\n",
    "            ranking = stats.find_all('rank')\n",
    "            for rank in ranking:\n",
    "                ranks[rank.get('friendlyname')] = rank.get('value')\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    #     get historical sales data\n",
    "        try:\n",
    "            sales_history = bg.find('marketplacehistory')\n",
    "            listings = sales_history.find_all('listing')\n",
    "            date_format = '%a, %d %b %Y %H:%M:%S +0000'\n",
    "            marketplace_history = {}\n",
    "            for i, listing in enumerate(listings):\n",
    "                listdate = datetime.strptime(listing.find('listdate').text, date_format)\n",
    "                saledate = datetime.strptime(listing.find('saledate').text, date_format)\n",
    "                delta = saledate - listdate\n",
    "                saletime = delta.days*24*60*60 + delta.seconds\n",
    "                unix_saledate = int(datetime.timestamp(saledate))\n",
    "\n",
    "                price = listing.find('price').text\n",
    "                currency = listing.find('price').get('currency')\n",
    "                condition = listing.find('condition').text\n",
    "\n",
    "                marketplace_history[i] = {'unix_saledate':unix_saledate, 'saletime':saletime, \n",
    "                                         'price':price, 'currency':currency, 'condition':condition}\n",
    "        except:\n",
    "            marketplace_history = {}\n",
    "\n",
    "\n",
    "    #     get real sales data\n",
    "        try:\n",
    "            sales_history = bg.find('marketplacelistings')\n",
    "            listings = sales_history.find_all('listing')\n",
    "            marketplace_listings = {}\n",
    "            for i, listing in enumerate(listings):\n",
    "                listdate = datetime.strptime(listing.find('listdate').text, date_format)\n",
    "                unix_listdate = int(datetime.timestamp(listdate))\n",
    "\n",
    "                price = listing.find('price').text\n",
    "                currency = listing.find('price').get('currency')\n",
    "                condition = listing.find('condition').text\n",
    "\n",
    "                marketplace_listings[i] = {'unix_listdate':unix_listdate,\n",
    "                                         'price':price, 'currency':currency, 'condition':condition}\n",
    "        except:\n",
    "            marketplace_listings = {}\n",
    "\n",
    "        game = {'boardgame_id':boardgame_id, 'title': title, 'year_published':year_published, 'minplayers':minplayers, 'maxplayers':maxplayers, \n",
    "                'minplaytime': minplaytime, 'maxplaytime':maxplaytime, 'age':age, 'users_rated':users_rated, \n",
    "                'average_rating':average_rating, 'bayes_average_rating':bayes_average_rating, 'median':median, \n",
    "                'stddev':stddev, 'owned':owned, 'trading':trading, 'wishing':wishing, 'num_of_comments':num_of_comments, \n",
    "                'num_of_weights':num_of_weights, 'average_weight':average_weight, 'ranks':ranks, \n",
    "                'main_publisher':main_publisher, \n",
    "                'description':description, 'publishers':publishers, 'honors':honors, 'expansions':expansions, \n",
    "                'accessories':accessories, 'artists':artists, 'mechanics':mechanics, 'category':category, \n",
    "                'designers':designers, 'graphic_designers':graphic_designers, 'subdomains':subdomains, \n",
    "                'implementations':implementations, 'suggested_numplayers':suggested_numplayers,\n",
    "                'podcast_episodes':podcast_episodes, 'comments':comments, 'marketplace_history':marketplace_history, \n",
    "                'marketplace_listings':marketplace_listings}\n",
    "        games = pd.concat([games, pd.DataFrame([game])])\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028481a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ratings(nickname, sleep=True):\n",
    "    '''\n",
    "    This function takes the boardgamegeek.com username as input \n",
    "    and returns a pandas DataFrame with all of the user's scores\n",
    "    '''\n",
    "    url_coll_main = 'https://api.geekdo.com/xmlapi/collection/'\n",
    "    params = '?rated=1'\n",
    "    \n",
    "    if sleep: \n",
    "        r = re.get(url_coll_main + nickname + params)\n",
    "        time.sleep(14.66)\n",
    "    time.sleep(0.33)\n",
    "    r = re.get(url_coll_main + nickname + params)\n",
    "    soup = BeautifulSoup(r.text, features=\"xml\")\n",
    "    ratings = pd.DataFrame()\n",
    "    rows = soup.find_all('item')\n",
    "    for item in rows:\n",
    "        boardgame_id = item.get('objectid')\n",
    "        try:\n",
    "            title = item.find('name').text\n",
    "        except:\n",
    "            title = ''\n",
    "        try:\n",
    "            rating = item.find('stats').find('rating').get('value')\n",
    "        except:\n",
    "            rating = ''\n",
    "        try:\n",
    "            num_of_plays = item.find('numplays').text\n",
    "        except:\n",
    "            num_of_plays = ''\n",
    "        try:\n",
    "            comment = item.find('comment').text\n",
    "        except:\n",
    "            comment = ''\n",
    "\n",
    "        status = item.find('status')\n",
    "        own = status.get('own')\n",
    "        prevowned = status.get('prevowned')\n",
    "        fortrade = status.get('fortrade')\n",
    "        want = status.get('want')\n",
    "        wanttoplay = status.get('wanttoplay')\n",
    "        wanttobuy = status.get('wanttobuy')\n",
    "        wishlist = status.get('wishlist') \n",
    "        preordered = status.get('preordered')\n",
    "        last_modified = status.get('lastmodified')\n",
    "\n",
    "\n",
    "        vote = {'nickname':nickname, 'title': title, 'boardgame_id':boardgame_id, 'rating':rating, \n",
    "                'num_of_plays':num_of_plays, \n",
    "                    'comment': comment, 'own':own, 'prevowned':prevowned, 'fortrade':fortrade, \n",
    "                    'want':want, 'wanttoplay':wanttoplay, 'wanttobuy':wanttobuy, \n",
    "                    'wishlist':wishlist, 'preordered':preordered, 'last_modified':last_modified}\n",
    "        ratings = pd.concat([ratings, pd.DataFrame([vote])])\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60aa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_for_country(country):\n",
    "    '''\n",
    "    This function allows you to retrieve public information about BoardGameGeek.com users, \n",
    "    such as nicknames, links to their profiles and the countries, states and sities listed on their profiles.\n",
    "    \n",
    "    Parameter\n",
    "    ----------\n",
    "    country: str, function wiil search uers from this country\n",
    "    '''\n",
    "    url_main = 'https://boardgamegeek.com/users/page/'\n",
    "    url_params = '?country='\n",
    "#     country = 'United States'#'England'\n",
    "\n",
    "    r = re.get(url_main + '1' + url_params + country)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    last_page = int(soup.find('a', title='last page').text.strip('[]'))\n",
    "\n",
    "    user_board = pd.DataFrame()\n",
    "\n",
    "    for page in tqdm_notebook(range(last_page)):\n",
    "        if page > 0:\n",
    "            time.sleep(0.33)\n",
    "            r = re.get(url_main + str(page+1) + url_params + country)\n",
    "            soup = BeautifulSoup(r.text)\n",
    "            \n",
    "        users = soup.find('table', class_='forum_table').find_all('div', class_='avatarblock')\n",
    "        for user in users:\n",
    "            link = user.find('div', class_='username').find('a').get('href')\n",
    "            location = str(user.find('div', class_='location'))\n",
    "            state_cuty = location[location.find(country):]\n",
    "            nickname = user.get('data-username')\n",
    "            user_name = {'link':link, 'nickname':nickname, 'country':country, 'state_cuty': state_cuty}\n",
    "            user_board = pd.concat([user_board, pd.DataFrame([user_name])])\n",
    "    return user_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_for_country_step_by_step(country, start_p=1, n_pages=5000):\n",
    "    '''\n",
    "    Modification function 'get_users_for_country', witch help to get info from countries with lot's of users, \n",
    "    like a USA.\n",
    "    \n",
    "    This function allows you to retrieve public information about BoardGameGeek.com users, \n",
    "    such as nicknames, links to their profiles and the countries, states and sities listed on their profiles.\n",
    "    \n",
    "    Parameter\n",
    "    ----------\n",
    "    country: str, function wiil search uers from this country\n",
    "    '''\n",
    "    url_main = 'https://boardgamegeek.com/users/page/'\n",
    "    url_params = '?country='\n",
    "#     country = 'United States'#'England'\n",
    "\n",
    "    r = re.get(url_main + str(start_p) + url_params + country)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    try: \n",
    "        last_page = int(soup.find('a', title='last page').text.strip('[]'))\n",
    "        if last_page-start_p < n_pages:\n",
    "            n_pages = last_page-start_p\n",
    "    except: \n",
    "        pass\n",
    "    user_board = pd.DataFrame()\n",
    "\n",
    "    for page in tqdm_notebook(range(n_pages)):\n",
    "        if page > 0:\n",
    "            time.sleep(0.5)\n",
    "            r = re.get(url_main + str(page+start_p) + url_params + country)\n",
    "            soup = BeautifulSoup(r.text)\n",
    "            \n",
    "        users = soup.find('table', class_='forum_table').find_all('div', class_='avatarblock')\n",
    "        for user in users:\n",
    "            link = user.find('div', class_='username').find('a').get('href')\n",
    "            location = str(user.find('div', class_='location'))\n",
    "            state_cuty = location[location.find(country):]\n",
    "            nickname = user.get('data-username')\n",
    "            user_name = {'link':link, 'nickname':nickname, 'country':country, 'state_cuty': state_cuty}\n",
    "            user_board = pd.concat([user_board, pd.DataFrame([user_name])])\n",
    "    return user_board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc04e0",
   "metadata": {},
   "source": [
    "# Get top 2000 board games "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_games = bgg_top(n_pages=20, start_page=1)\n",
    "# top_games.to_csv('bgg_top_2000_games.csv', index=False)\n",
    "top_games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f72a2",
   "metadata": {},
   "source": [
    "# Get main list of board games' categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = get_bgg_categories()\n",
    "# categories.to_csv('bgg_categories.csv', index=False)\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cad3bf7",
   "metadata": {},
   "source": [
    "# Scrap users' collections data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4078657",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "checked = pd.read_csv('checked_nicknames.csv')\n",
    "nicknames = pd.read_csv('test_bgg_users.csv')\n",
    "nicknames = list(set(nicknames.nickname) - set(checked.nicknames))\n",
    "rates = pd.DataFrame()\n",
    "test_nn = nicknames[:5000]\n",
    "print(f'Checked {len(checked)}, in progress {len(test_nn)}, left {len(nicknames)-len(test_nn)} nicknames')\n",
    "for nn in tqdm_notebook(test_nn):\n",
    "    get_user_ratings(nn, sleep=False)\n",
    "for i, nn in tqdm_notebook(enumerate(test_nn)):\n",
    "    rates = pd.concat([rates,get_user_ratings(nn, sleep=False)])\n",
    "#     if (i+1)%100==0: \n",
    "#         rates.to_csv('ratings_tmp.csv', index=False)\n",
    "        \n",
    "print(f'{len(rates)} rows added')\n",
    "checked = pd.concat([checked,pd.DataFrame(test_nn, columns=['nicknames'])])\n",
    "dt = datetime.now()\n",
    "rates.to_csv(f'bgg_ratings_{dt.year}_{dt.month}_{dt.day}_{dt.hour}_{dt.minute}_{dt.second}_{len(test_nn)}.csv', index=False)\n",
    "checked.to_csv(f'checked_nicknames.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "checked = pd.read_csv('checked_nicknames.csv')\n",
    "nicknames = pd.read_csv('test_bgg_users.csv')\n",
    "nicknames = list(set(nicknames.nickname) - set(checked.nicknames))\n",
    "rates = pd.DataFrame()\n",
    "test_nn = nicknames[:5000]\n",
    "print(f'Checked {len(checked)}, in progress {len(test_nn)}, left {len(nicknames)-len(test_nn)} nicknames')\n",
    "for nn in tqdm_notebook(test_nn):\n",
    "    get_user_ratings(nn, sleep=False)\n",
    "for i, nn in tqdm_notebook(enumerate(test_nn)):\n",
    "    rates = pd.concat([rates,get_user_ratings(nn, sleep=False)])\n",
    "#     if (i+1)%100==0: \n",
    "#         rates.to_csv('ratings_tmp.csv', index=False)\n",
    "        \n",
    "print(f'{len(rates)} rows added')\n",
    "checked = pd.concat([checked,pd.DataFrame(test_nn, columns=['nicknames'])])\n",
    "dt = datetime.now()\n",
    "rates.to_csv(f'bgg_ratings_{dt.year}_{dt.month}_{dt.day}_{dt.hour}_{dt.minute}_{dt.second}_{len(test_nn)}.csv', index=False)\n",
    "checked.to_csv(f'checked_nicknames.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b4b59",
   "metadata": {},
   "source": [
    "# Scrap boardgame data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d655f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists_of_ids = []\n",
    "for it in range(len(unique_ids)//50+1):\n",
    "    if it < len(unique_ids)//50+1:\n",
    "        list_of_lists_of_ids.append(unique_ids[it*50:50+it*50])\n",
    "    else:\n",
    "        list_of_lists_of_ids.append(unique_ids[it*50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf65207",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ids = []\n",
    "for it in range(len(new_bg_id)//50):\n",
    "    list_ids.append(new_bg_id[it*50:it*50+50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ff727",
   "metadata": {},
   "outputs": [],
   "source": [
    "boardgame_info = pd.DataFrame()\n",
    "for i in tqdm_notebook(range(len(list_ids))):\n",
    "    boardgame_info = pd.concat([boardgame_info,get_api_bgg_game_data(list_ids[i])])\n",
    "    time.sleep(0.33)\n",
    "#     break\n",
    "boardgame_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boardgame_info.to_csv('bgg_boardgames.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf99fc0",
   "metadata": {},
   "source": [
    "# Scrap nicknames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_countries = ['Abkhazia', 'Adjara', 'Afghanistan', 'Akrotiri and Dhekelia', 'Åland', 'Albania', \n",
    "                         'Algeria', 'American Samoa', 'Andorra', 'Angola', 'Anguilla', 'Antarctica', \n",
    "                         'Antigua and Barbuda', 'APO/FPO', 'Argentina', 'Armenia', 'Aruba', 'Ascension Island', \n",
    "                         'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', \n",
    "                         'Belarus', 'Belgium', 'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia', 'Bonaire', \n",
    "                         'Bosnia and Herzegovina', 'Botswana', 'Bouvet Island', 'Brazil', \n",
    "                         'British Indian Ocean Territory', 'British Virgin Islands', 'Brunei', 'Bulgaria', \n",
    "                         'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cape Verde', \n",
    "                         'Cayman Islands', 'Central African Republic', 'Chad', 'Chile', 'China', 'Christmas Island', \n",
    "                         'Cocos [Keeling] Islands', 'Colombia', 'Comoros', 'Cook Islands', 'Costa Rica', 'Croatia', \n",
    "                         'Cuba', 'Curacao', 'Cyprus', 'Czech Republic', 'Democratic Republic of the Congo', \n",
    "                         'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'East Timor', 'Ecuador', 'Egypt', \n",
    "                         'El Salvador', 'England', 'Equatorial Guinea', 'Eritrea', 'Estonia', 'Ethiopia', \n",
    "                         'Falkland Islands', 'Faroe Islands', 'Fiji', 'Finland', 'France', 'French Guiana', \n",
    "                         'French Polynesia', 'French Southern Territories', 'Gabon', 'Gambia', 'Georgia', 'Germany', \n",
    "                         'Ghana', 'Gibraltar', 'Greece', 'Greenland', 'Grenada', 'Guadeloupe', 'Guam', 'Guatemala', \n",
    "                         'Guernsey', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', \n",
    "                         'Heard Island and McDonald Islands', 'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India', \n",
    "                         'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Isle of Man', 'Israel', 'Italy', 'Ivory Coast', \n",
    "                         'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kazakhstan', 'Kenya', 'Kiribati', 'Kosovo', \n",
    "                         'Kuwait', 'Kyrgyzstan', 'Laos', 'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', \n",
    "                         'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macao', 'Macedonia', 'Madagascar', 'Malawi', \n",
    "                         'Malaysia', 'Maldives', 'Mali', 'Malta', 'Marshall Islands', 'Martinique', 'Mauritania', \n",
    "                         'Mauritius', 'Mayotte', 'Mexico', 'Micronesia', 'Moldova', 'Monaco', 'Mongolia', \n",
    "                         'Montenegro', 'Montserrat', 'Morocco', 'Mozambique', 'Myanmar [Burma]', 'Nagorno-Karabakh', \n",
    "                         'Namibia', 'Nauru', 'Nepal', 'Netherlands', 'Netherlands Antilles', 'New Caledonia', \n",
    "                         'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'Niue', 'Norfolk Island', 'North Korea', \n",
    "                         'Northern Mariana Islands', 'Norway', 'Oman', 'Other-Africa', 'Other-Asia', \n",
    "                         'Other-Eastern Europe', 'Other-Middle East', 'Other-South Pacific', 'Pakistan', 'Palau', \n",
    "                         'Palestine', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', \n",
    "                         'Pitcairn Islands', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Republic of the Congo', \n",
    "                         'Réunion', 'Romania', 'Russia', 'Rwanda', 'Saint Barthélemy', 'Saint Helena', \n",
    "                         'Saint Kitts and Nevis', 'Saint Lucia', 'Saint Martin', 'Saint Pierre and Miquelon', \n",
    "                         'Saint Vincent and the Grenadines', 'Samoa', 'San Marino', 'São Tomé and Príncipe', \n",
    "                         'Saudi Arabia', 'Scotland', 'Senegal', 'Serbia', 'Seychelles', 'Sierra Leone', 'Singapore', \n",
    "                         'Sint Maarten', 'Slovakia', 'Slovenia', 'Solomon Islands', 'Somalia', 'South Africa', \n",
    "                         'South Georgia and the South Sandwich Islands', 'South Korea', 'South Sudan', 'Spain', \n",
    "                         'Sri Lanka', 'Sudan', 'Suriname', 'Svalbard and Jan Mayen', 'Swaziland', 'Sweden', \n",
    "                         'Switzerland', 'Syria', 'Taiwan', 'Tajikistan', 'Tanzania', 'Thailand', 'Togo', 'Tokelau', \n",
    "                         'Tonga', 'Trinidad and Tobago', 'Tristan da Cunha', 'Tunisia', 'Turkey', 'Turkmenistan', \n",
    "                         'Turks and Caicos Islands', 'Tuvalu', 'Uganda', 'Ukraine', 'United Arab Emirates', \n",
    "                         'United Kingdom', 'United States', 'Uruguay', 'U.S. Minor Outlying Islands', \n",
    "                         'U.S. Virgin Islands', 'Uzbekistan', 'Vanuatu', 'Vatican City', 'Venezuela', 'Vietnam', \n",
    "                         'Wales', 'Wallis and Futuna', 'Western Sahara', 'Yemen', 'Zambia', 'Zimbabwe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "boardgame_users = get_users_for_country_step_by_step('Bonaire', start_p=1, n_pages=1)\n",
    "# boardgame_users = get_users_for_country('Spain')\n",
    "\n",
    "# bgg_users = pd.DataFrame()\n",
    "bgg_users = pd.read_csv('bgg_users.csv')\n",
    "bgg_users = pd.concat([bgg_users, boardgame_users])\n",
    "bgg_users.drop_duplicates()\n",
    "bgg_users.to_csv('bgg_users.csv', index=False)\n",
    "bgg_users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

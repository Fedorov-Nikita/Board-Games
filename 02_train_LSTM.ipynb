{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc6be4fc",
   "metadata": {},
   "source": [
    "# Import libs and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "eebab5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class CFG:\n",
    "    PATH_TO_DB = './data/board_games.sqlite'\n",
    "    PATH_FOR_TMP_BG_FILES = './data/scraped/bgg_boardgame_tmp'\n",
    "    PATH_FOR_TMP_USER_FILES = './data/scraped/bgg_user_tmp'\n",
    "    PATH_TO_SAVE_USER_FILES = './data/scraped/bgg_user'\n",
    "    PATH_TO_TMP_FILES = './data/scraped/tmp'\n",
    "    PATH_FOR_MODEL = './model.pt'\n",
    "    \n",
    "    # Model train parameters\n",
    "    BATCH_SIZE = 256\n",
    "    SHUFFLE_TRAIN_DATASET = True\n",
    "    TRAIN_EPOCHS = 100\n",
    "    LEARNING_RATE = 3e-4\n",
    "    \n",
    "    # Main torch parameters\n",
    "    USE_GPU = torch.cuda.is_available()\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Metrics parameters\n",
    "    K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0bac7",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "В работе для более полной оценки результатов и сравнения моделей будем использовать несколько метрик использующихся для оценки поисковых и ранжирующих систем, поэтому мы и будем использовать их для оценки рекомендательной системы:\n",
    "MAP@k, NDCG@k и MRR@k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21a8165",
   "metadata": {},
   "source": [
    "У нас будет 1 ответ для рекомендаций пользователей, поэтому напишем свою реализацию NDCG, которая будет работать с нашим выходои модели. Так как правильный ответ один, то IDCG всегда будет равен 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "a302dc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5327324383928644"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DCG_score(true, pred, k):\n",
    "    '''\n",
    "    Return: np.array of DCG@k for each sample in batch.\n",
    "    -----\n",
    "    Pred: np.array - array of predicted games' ids\n",
    "    True: np.array - array of real next game in seq\n",
    "    k: int - only consider the highest k scores in the ranking\n",
    "    '''\n",
    "    if k > 0:\n",
    "        pred = pred[:,:k]\n",
    "    \n",
    "    result_possition = np.where(pred == true)[1] + 1 # rank starts from 1\n",
    "    DCG = 1/np.log2(result_possition + 1)\n",
    "    if len(true)!= len(DCG):\n",
    "        for i in range(len(true) - len(DCG)):\n",
    "            DCG = np.concatenate((DCG, [0.]))\n",
    "    return DCG\n",
    "\n",
    "def NDCG_score(true, pred, k=5): # NDCG = DCG/IDCG, but IDCG = 1\n",
    "    '''\n",
    "    Return: NDCG@k for batch\n",
    "    -----\n",
    "    Pred: np.array - array of predicted games' ids\n",
    "    True: np.array - array of real next game in seq\n",
    "    '''\n",
    "\n",
    "    return np.mean(DCG_score(true, pred, k=k)) \n",
    "\n",
    "NDCG_score(np.array(([4],[5],[6],[7])),\n",
    "    np.array(([1,2,4,5,1,2], [1,5,3,4,2,7], [6,4,1,8,5,3], [1,2,3,4,8,7])), k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694696a",
   "metadata": {},
   "source": [
    "MAP также будет рассчитываться исходя из того, что у нас только 1 правильный ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "e534a8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4583333333333333"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ap(true, pred, k):\n",
    "    '''\n",
    "    Return: np.array of APs@k for each sample in batch.\n",
    "    -----\n",
    "    Pred: np.array - array of predicted games' ids\n",
    "    True: np.array - array of real next game in seq\n",
    "    '''\n",
    "    if k > 0:\n",
    "        pred = pred[:,:k]\n",
    "        \n",
    "#     for i, yp_item in enumerate(y_pred):\n",
    "    \n",
    "#     k = i+1 # our rank starts at 1\n",
    "#     correct_predictions = 0\n",
    "#     running_sum = 0\n",
    "\n",
    "#     if yp_item in y_true:\n",
    "#         correct_predictions += 1\n",
    "#         running_sum += correct_predictions/k\n",
    "    APs = 1 / (np.where(pred == true)[1] + 1)\n",
    "    if len(true) != len(APs):\n",
    "        for i in range(len(true) - len(APs)):\n",
    "            APs = np.concatenate((APs, [0.]))\n",
    "    return APs\n",
    "\n",
    "def MAP_score(true, pred, k=5):\n",
    "    '''\n",
    "    Return: MAP@k for batch\n",
    "    -----\n",
    "    Pred: np.array - array of predicted games' ids\n",
    "    True: np.array - array of real next game in seq\n",
    "    '''\n",
    "    return np.mean(ap(true, pred, k=k))\n",
    "\n",
    "MAP_score(np.array(([4],[5],[6],[7])),\n",
    "    np.array(([1,2,4,5,1,2], [1,5,3,4,2,7], [6,4,1,8,5,3], [1,2,3,4,8,7])), k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c267c98",
   "metadata": {},
   "source": [
    "# Load dataset and create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6c288da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedReader.close>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"./data/games_seq.np\", \"rb\")\n",
    "games_arr = np.load(file)\n",
    "file.close\n",
    "\n",
    "file = open(\"./data/scores_seq.np\", \"rb\")\n",
    "scores_arr = np.load(file)\n",
    "file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b8ab0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GamesSeqDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, ids, scores):\n",
    "        self.ids = torch.IntTensor(ids)\n",
    "        self.scores = torch.from_numpy(scores).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ids.shape[0]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        return (self.ids[index], self.scores[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "053d9967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4993508, 2140076)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_train, g_test, s_train, s_test = train_test_split(games_arr, scores_arr, test_size=0.3, random_state=42)\n",
    "len(g_train), len(g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8041ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GamesSeqDataset(g_train, s_train)\n",
    "val_dataset = GamesSeqDataset(g_test, s_test)  \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=CFG.SHUFFLE_TRAIN_DATASET) \n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "08b399f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[205896, 169786, 157969,  ..., 170216,  35677, 291457],\n",
      "        [205059, 193214,     18,  ..., 192547,  40834,     93],\n",
      "        [ 88282, 151022, 174301,  ...,  61001,  10630,   9209],\n",
      "        ...,\n",
      "        [   527, 286616, 173574,  ...,   4086,   7854, 136955],\n",
      "        [ 36218,  35435,  27356,  ...,  21790,  21763,   1597],\n",
      "        [141007,  39938, 177352,  ..., 127023, 139993, 135654]],\n",
      "       dtype=torch.int32) tensor([[ 0.0529,  0.0529, -0.9471,  ...,  1.0529,  0.0529,  1.0529],\n",
      "        [ 1.5377,  0.5377, -0.4623,  ..., -0.9623, -0.9623,  0.0377],\n",
      "        [ 0.1596,  0.4696,  0.4696,  ...,  0.2096,  0.4496, -0.4404],\n",
      "        ...,\n",
      "        [-0.4367,  0.5633, -0.4367,  ...,  1.5633, -0.4367,  0.5633],\n",
      "        [ 0.2140,  0.2140, -0.2860,  ..., -0.2860, -0.2860, -0.2860],\n",
      "        [-0.7692, -0.7692,  0.2308,  ...,  0.2308, -0.7692,  1.2308]])\n"
     ]
    }
   ],
   "source": [
    "for g, s in train_loader:\n",
    "    print(g, s)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6d7a7",
   "metadata": {},
   "source": [
    "# Create model\n",
    "Мы будем использовать структуру основанную на [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#lstm) и линейных слоях, в качестве лосса будем использовать косунусную близость ([COSINEEMBEDDINGLOSS](https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html#cosineembeddingloss))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "1d647437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72344"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = list(set(games_arr.reshape(-1)))\n",
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "beddf242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 385643)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(all_ids), max(all_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edbf8d9",
   "metadata": {},
   "source": [
    "Будем использовать значения id так, как они еспользуются в базе, так как впоследствие при дообучении можно будет дообучать модель на последовательностях с отсутствующими в текущий момент играми, поэтому с запасом выделим 400 000 id для эмбеддингов, а из результатов будем исключать отсутствующие в обучающей выборке игры с помощью списка all_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "8372824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysLSTM(nn.Module):\n",
    "    def __init__(self, num_items, actual_ids, embedding_dim=16, hidden_dim=64, ):\n",
    "        super(RecSysLSTM, self).__init__()\n",
    "        self.item_embed = nn.Embedding(num_items, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim+1, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, embedding_dim)\n",
    "        self.linear_for_answer = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.actual_ids = actual_ids\n",
    "        \n",
    "    def result_inference(self, result):\n",
    "        result = self.item_embed(result)\n",
    "        result = F.relu(self.linear_for_answer(result))\n",
    "        result = F.relu(self.linear_for_answer(result))\n",
    "        return result\n",
    "\n",
    "    def forward(self, item_seq, score_seq, result=None):\n",
    "        item_embeds = self.item_embed(item_seq)\n",
    "        item_embeds = torch.cat([item_embeds, score_seq.reshape(item_seq.shape[0], item_seq.shape[1], -1)], dim=2)\n",
    "#         print('item_embeds', item_embeds.shape, 'score_seq', score_seq.shape)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(item_embeds.view(item_seq.shape[0], item_seq.shape[1], -1))\n",
    "        output = F.relu(self.linear(lstm_out))[:,-1,:]\n",
    "\n",
    "        if not result is None:\n",
    "            result = self.result_inference(result)\n",
    "#             print('output', output.shape, 'result', result.shape)\n",
    "            return output, result\n",
    "\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "8d42a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecSysLSTM(num_items=400000, actual_ids=all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "9a027647",
   "metadata": {},
   "outputs": [],
   "source": [
    "o, r = model(g[:,:-1], s[:,:-1], g[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b38b5b",
   "metadata": {},
   "source": [
    "# Create train function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32f6f2",
   "metadata": {},
   "source": [
    "Для оценки метрик надо в процессе обучения сравнивать со всеми инференсами, поэтому логично для экономия времени вычислений делать это по окончании какой-либо эпохи, получив векторы для всех игр один раз на инференсе и сравнив их с выходами модели после LSTM для каждой последовательности, чтобы получить ранжирование всех результатов после эпохи. Так как это довольно долгий процесс будем делать это после каждой 5й эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "fd303ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(all_ids, model, train_loader, test_loader, k=CFG.K, break_=None):\n",
    "    \"\"\"\n",
    "    Function for validate model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # create tensor for all_ids\n",
    "    all_ids_tensor = torch.IntTensor(all_ids) \n",
    "    \n",
    "    #\n",
    "    all_ids_predictions = model.result_inference(all_ids_tensor).unsqueeze(0) # shape (n_games, 1, embedding_dim)\n",
    "\n",
    "    ndsg_k = 0.\n",
    "    map_k = 0.\n",
    "    iter_counter = 0\n",
    "\n",
    "    # iterate in train_loader\n",
    "    for games, scores in tqdm(train_loader):\n",
    "        \n",
    "        # calculate cosine similarity between batch and all games (shape=(n_games, batch_size))\n",
    "        cosine_similarity_tensor = F.cosine_similarity(all_ids_predictions,\n",
    "                                                       model(games[:,:-1], scores[:,:-1]).unsqueeze(1), \n",
    "                                                       dim=2)\n",
    "\n",
    "        # get topk ids for each output in batch (shape=(batch_size, k))\n",
    "        batch_topk_ids = all_ids_tensor[torch.topk(cosine_similarity_tensor, k=k, dim=1).indices]\n",
    "        \n",
    "        ndsg_k += NDCG_score(games[:,-1:], batch_topk_ids, k=CFG.K)\n",
    "        map_k += MAP_score(games[:,-1:], batch_topk_ids, k=CFG.K)\n",
    "        iter_counter += 1\n",
    "#         print(f'Iteration {iter_counter}')\n",
    "        if iter_counter == break_:\n",
    "            break\n",
    "        \n",
    "    ndsg_k_train = ndsg_k / iter_counter\n",
    "    map_k_train = map_k / iter_counter\n",
    "    \n",
    "    # reset constants for validation test data\n",
    "    ndsg_k = 0.\n",
    "    map_k = 0.\n",
    "    iter_counter = 0\n",
    "\n",
    "    # iterate in test_loader\n",
    "    for games, scores in tqdm(test_loader):\n",
    "        \n",
    "        # calculate cosine similarity between batch and all games (shape=(n_games, batch_size))\n",
    "        cosine_similarity_tensor = F.cosine_similarity(all_ids_predictions,\n",
    "                                                       model(games[:,:-1], scores[:,:-1]).unsqueeze(1), \n",
    "                                                       dim=2)\n",
    "\n",
    "        # get topk ids for each output in batch (shape=(batch_size, k))\n",
    "        batch_topk_ids = all_ids_tensor[torch.topk(cosine_similarity_tensor, k=k, dim=1).indices]\n",
    "        \n",
    "        ndsg_k += NDCG_score(games[:,-1:], batch_topk_ids, k=CFG.K)\n",
    "        map_k += MAP_score(games[:,-1:], batch_topk_ids, k=CFG.K)\n",
    "        iter_counter += 1\n",
    "#         print(f'Iteration {iter_counter}')\n",
    "        if iter_counter == break_:\n",
    "            break\n",
    "        \n",
    "    ndsg_k_test = ndsg_k / iter_counter\n",
    "    map_k_test = map_k / iter_counter\n",
    "    \n",
    "    \n",
    "    print(f'NDCG@k\\ttrain:\\t{ndsg_k_train}\\ttest:\\t{ndsg_k_test}')\n",
    "    print(f'MAP@k\\ttrain:\\t{map_k_train}\\ttest:\\t{map_k_test}')\n",
    "    return ndsg_k_train, ndsg_k_test, map_k_train, map_k_test\n",
    "\n",
    "# validate_model(all_ids, model=model, train_loader=train_loader, test_loader=val_loader, k=CFG.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "587711ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss_function, optimizer, epochs=CFG.TRAIN_EPOCHS, validate=False, break_=None):\n",
    "    \"\"\"\n",
    "    Function for training model for recomendation system.\n",
    "    \n",
    "    Return: If validate is 'False' func returns train losses, if 'True' - losses and metrics\n",
    "    \n",
    "    ==========\n",
    "    Parameters:\n",
    "    model - PyTorch model based on nn.Module\n",
    "    train_loader - PyTorch DataLoader object with train data\n",
    "    val_loader - PyTorch DataLoader object with validation data\n",
    "    loss_function - PyTorch loss function\n",
    "    optimizer - PyTorch optimizer\n",
    "    epochs: int - number of traiing epochs\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        train_ndcg = []\n",
    "        val_ndcg = []\n",
    "        train_map = []\n",
    "        val_map = []\n",
    "        \n",
    "        train_loss = 0.\n",
    "        it = 0\n",
    "        \n",
    "        for games, scores in train_loader:\n",
    "            model.train()\n",
    "            \n",
    "            games = games.to(CFG.DEVICE)\n",
    "            scores = scores.to(CFG.DEVICE)\n",
    "            \n",
    "            output, target = model(games[:,:-1], scores[:,:-1], games[:,-1])\n",
    "\n",
    "            loss = loss_function(output, \n",
    "                                 target, \n",
    "                                 torch.Tensor([1 for _ in range(len(output))])) # because we use only positive samples\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss = loss.mean().item()\n",
    "            it += 1\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            if it == break_:\n",
    "                break\n",
    "\n",
    "        if ((epoch+1) % 5 == 0) and validate:\n",
    "            print(f'==========\\tEPOCH #{epoch+1}\\t==========')\n",
    "            train_ndcg, val_ndcg, train_map, val_map = validate_model(all_ids=all_ids, \n",
    "                                                                      model=model, \n",
    "                                                                      train_loader=train_loader, \n",
    "                                                                      test_loader=val_loader, \n",
    "                                                                      k=CFG.K, \n",
    "                                                                      break_=None)\n",
    "            \n",
    "    if validate:\n",
    "        return train_losses, train_ndcg, val_ndcg, train_map, val_map\n",
    "    else:\n",
    "        return train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "25354157",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecSysLSTM(num_items=400000, actual_ids=all_ids)#.to(CFG.DEVICE)\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG.LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "609b834a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2e535c94a74addb5e8a89375061b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 8min 54s, sys: 16min 4s, total: 1h 24min 59s\n",
      "Wall time: 22min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "losses = train_model(model=model, \n",
    "            train_loader=train_loader, \n",
    "            val_loader=val_loader, \n",
    "            loss_function=criterion, \n",
    "            optimizer=optimizer,\n",
    "            epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "0ae931dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383d02e489d5459e912db1981c9eeef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19506 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96dcaea60fd421f91ad0766ada4c406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@k\ttrain:\t0.00022554652086911157\ttest:\t0.0002274347871783394\n",
      "MAP@k\ttrain:\t0.00012956869688752738\ttest:\t0.00013146732539207827\n",
      "CPU times: user 2d 9h 44min 56s, sys: 22h 58min 30s, total: 3d 8h 43min 27s\n",
      "Wall time: 1d 22h 44min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00022554652086911157,\n",
       " 0.0002274347871783394,\n",
       " 0.00012956869688752738,\n",
       " 0.00013146732539207827)"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "validate_model(all_ids, model=model, train_loader=train_loader, test_loader=val_loader, k=CFG.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c8c71",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "812de3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, CFG.PATH_FOR_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0856f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load(CFG.PATH_FOR_MODEL)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

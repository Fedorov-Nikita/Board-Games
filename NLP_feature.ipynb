{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26287fc0",
   "metadata": {},
   "source": [
    "## Description\n",
    "This feature is based on Transformers and the final interaction with it is as follows:\n",
    "- The text is fed to the input\n",
    "- Text preprocessing takes place\n",
    "- Text tokenization\n",
    "- Inference using Transformer\n",
    "- Calculating cosine distances to nearest (in latent space) game descriptions / Finding nearest neighbors\n",
    "- Sorting and displaying the top of recommended games matching the user's description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "46c09560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "import html\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4990ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    PATH_TO_DB = './data/board_games.sqlite'\n",
    "    PATH_TO_EMBEDDINGS = './data/boardgames_embeddings.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb04181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|███████| 47.4M/47.4M [00:16<00:00, 2.89MB/s]\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e319e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[CLS]', '[SEP]', '<unk>', '<pad>', '[MASK]'], [2, 3, 1, 0, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens, tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f8953ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s\" really great'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r'<[^\\n\\r<>]+>', ' ', text)  # remove tags\n",
    "    text = re.sub(r'(http[s]?://)?[\\w\\.]+\\.[a-z]{2,3}[\\S]+', ' ', text)  # remove links\n",
    "    text = html.unescape(text)  # convert html symbols\n",
    "    return re.sub(r'[\\s]+', ' ', text)\n",
    "\n",
    "def get_text_embedding(text, tokenizer, model):\n",
    "    encoded_input = tokenizer(clean_text(text), return_tensors='pt', truncation=True)\n",
    "    output = model(**encoded_input)\n",
    "    return output.last_hidden_state[0][0].tolist()\n",
    "\n",
    "clean_text(\"It's&quot; really</br>     great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "2c18aa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 'Expansion for Base-game')"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(CFG.PATH_TO_DB)\n",
    "cursor = conn.cursor()\n",
    "category = 'Expansion for Base-game'\n",
    "cursor.execute('''\n",
    "                SELECT category_id, category\n",
    "                FROM categories\n",
    "                ''')\n",
    "categories = cursor.fetchall()\n",
    "conn.close()\n",
    "categories[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "61f9d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130973"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_id = 6, 28, 30, 47, 58\n",
    "\n",
    "conn = sqlite3.connect(CFG.PATH_TO_DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "                SELECT d.boardgame_id, d.description\n",
    "                FROM    (SELECT DISTINCT boardgame_id\n",
    "                         FROM boardgame_categories\n",
    "                         WHERE (category_id <> 6)) t\n",
    "                LEFT JOIN descriptions d ON d.boardgame_id = t.boardgame_id\n",
    "                ''')\n",
    "data = cursor.fetchall()\n",
    "conn.close()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ca0e34f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1d 23h 54min 44s, sys: 7h 13min 58s, total: 2d 7h 8min 43s\n",
      "Wall time: 23h 46min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = {}\n",
    "for game in data:\n",
    "    embeddings[game[0]] = get_text_embedding(clean_text(game[1]), tokenizer, model)\n",
    "# pd.DataFrame(embeddings).T.reset_index(names='boardgame_id').to_pickle(CFG.PATH_TO_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c074ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_games_for_request(text_request: str, tokenizer, model, PATH_TO_EMBEDDINGS, k=5):\n",
    "    df = pd.read_pickle(PATH_TO_EMBEDDINGS)#.iloc[:10]\n",
    "    request_embeddings = get_text_embedding(clean_text(text_request), tokenizer, model)\n",
    "    df['similarity'] = df.apply(lambda row: cosine_similarity([row[1:].to_list(), \n",
    "                                                               request_embeddings])[0][1], axis=1)\n",
    "    df = df.sort_values(by='similarity', ascending=False)\n",
    "    return df.boardgame_id.values[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6731300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.8 s, sys: 2.96 s, total: 45.8 s\n",
      "Wall time: 47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([233589, 162226,  94045,  27861, 233694])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text_request = 'some of the types of monopoly games'\n",
    "\n",
    "get_games_for_request(text_request=text_request, \n",
    "                      tokenizer=tokenizer, \n",
    "                      model=model, \n",
    "                      PATH_TO_EMBEDDINGS=CFG.PATH_TO_EMBEDDINGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
